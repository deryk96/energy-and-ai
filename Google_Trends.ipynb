{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9bcd630-88a6-43a2-a821-609a59111877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # to send HTTP requests\n",
    "import json      # optional, useful for pretty-printing JSON responses\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bedad61-9c8a-4f8d-a5e8-359f97929bdd",
   "metadata": {},
   "source": [
    "The code below allows me to pull the results of the query \"generative ai\" from google trends acrodd the US for the last month on a day to day basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ead151-0f11-4681-8cf4-0bc670f61f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending Searches DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Interest Over Time DataFrame:\n",
      "                                        timeline_data\n",
      "0   {'date': 'Oct 14, 2024', 'timestamp': '1728864...\n",
      "1   {'date': 'Oct 15, 2024', 'timestamp': '1728950...\n",
      "2   {'date': 'Oct 16, 2024', 'timestamp': '1729036...\n",
      "3   {'date': 'Oct 17, 2024', 'timestamp': '1729123...\n",
      "4   {'date': 'Oct 18, 2024', 'timestamp': '1729209...\n",
      "5   {'date': 'Oct 19, 2024', 'timestamp': '1729296...\n",
      "6   {'date': 'Oct 20, 2024', 'timestamp': '1729382...\n",
      "7   {'date': 'Oct 21, 2024', 'timestamp': '1729468...\n",
      "8   {'date': 'Oct 22, 2024', 'timestamp': '1729555...\n",
      "9   {'date': 'Oct 23, 2024', 'timestamp': '1729641...\n",
      "10  {'date': 'Oct 24, 2024', 'timestamp': '1729728...\n",
      "11  {'date': 'Oct 25, 2024', 'timestamp': '1729814...\n",
      "12  {'date': 'Oct 26, 2024', 'timestamp': '1729900...\n",
      "13  {'date': 'Oct 27, 2024', 'timestamp': '1729987...\n",
      "14  {'date': 'Oct 28, 2024', 'timestamp': '1730073...\n",
      "15  {'date': 'Oct 29, 2024', 'timestamp': '1730160...\n",
      "16  {'date': 'Oct 30, 2024', 'timestamp': '1730246...\n",
      "17  {'date': 'Oct 31, 2024', 'timestamp': '1730332...\n",
      "18  {'date': 'Nov 1, 2024', 'timestamp': '17304192...\n",
      "19  {'date': 'Nov 2, 2024', 'timestamp': '17305056...\n",
      "20  {'date': 'Nov 3, 2024', 'timestamp': '17305920...\n",
      "21  {'date': 'Nov 4, 2024', 'timestamp': '17306784...\n",
      "22  {'date': 'Nov 5, 2024', 'timestamp': '17307648...\n",
      "23  {'date': 'Nov 6, 2024', 'timestamp': '17308512...\n",
      "24  {'date': 'Nov 7, 2024', 'timestamp': '17309376...\n",
      "25  {'date': 'Nov 8, 2024', 'timestamp': '17310240...\n",
      "26  {'date': 'Nov 9, 2024', 'timestamp': '17311104...\n",
      "27  {'date': 'Nov 10, 2024', 'timestamp': '1731196...\n",
      "28  {'date': 'Nov 11, 2024', 'timestamp': '1731283...\n",
      "29  {'date': 'Nov 12, 2024', 'timestamp': '1731369...\n",
      "30  {'date': 'Nov 13, 2024', 'timestamp': '1731456...\n",
      "31  {'date': 'Nov 14, 2024', 'timestamp': '1731542...\n"
     ]
    }
   ],
   "source": [
    "# SERP API configuration\n",
    "api_key = 'd9a1fe6b31333b92203f396c6b8770a363fe43e109bdab8e5cb49106bcb7897e'\n",
    "endpoint = 'https://serpapi.com/search.json'\n",
    "query = 'generative AI'\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'engine': 'google_trends',\n",
    "    'q': query,\n",
    "    'date': 'today 1-m',  # Last month\n",
    "    'geo': 'US',  # Example: United States\n",
    "    'api_key': api_key\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(endpoint, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    # Trending Searches DataFrame\n",
    "    trending_data = data.get(\"trending_searches\", [])\n",
    "    trending_df = pd.DataFrame(trending_data)\n",
    "    \n",
    "    # Interest Over Time DataFrame\n",
    "    interest_data = data.get(\"interest_over_time\", [])\n",
    "    interest_df = pd.DataFrame(interest_data)\n",
    "    \n",
    "    print(\"Trending Searches DataFrame:\")\n",
    "    print(trending_df)\n",
    "    print(\"\\nInterest Over Time DataFrame:\")\n",
    "    print(interest_df)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b243bf81-c56a-49f8-8804-cfed82140b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand related_queries in trending_df\n",
    "if 'related_queries' in trending_df.columns:\n",
    "    related_queries_df = pd.json_normalize(trending_df['related_queries'].explode())\n",
    "    print(\"\\nRelated Queries DataFrame:\")\n",
    "    print(related_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62228c3-f5ec-489a-b06d-a0f63e91eb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeline_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'date': 'Oct 14, 2024', 'timestamp': '1728864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'date': 'Oct 15, 2024', 'timestamp': '1728950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'date': 'Oct 16, 2024', 'timestamp': '1729036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'date': 'Oct 17, 2024', 'timestamp': '1729123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'date': 'Oct 18, 2024', 'timestamp': '1729209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'date': 'Oct 19, 2024', 'timestamp': '1729296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'date': 'Oct 20, 2024', 'timestamp': '1729382...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'date': 'Oct 21, 2024', 'timestamp': '1729468...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'date': 'Oct 22, 2024', 'timestamp': '1729555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'date': 'Oct 23, 2024', 'timestamp': '1729641...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'date': 'Oct 24, 2024', 'timestamp': '1729728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'date': 'Oct 25, 2024', 'timestamp': '1729814...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'date': 'Oct 26, 2024', 'timestamp': '1729900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'date': 'Oct 27, 2024', 'timestamp': '1729987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'date': 'Oct 28, 2024', 'timestamp': '1730073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'date': 'Oct 29, 2024', 'timestamp': '1730160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'date': 'Oct 30, 2024', 'timestamp': '1730246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'date': 'Oct 31, 2024', 'timestamp': '1730332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'date': 'Nov 1, 2024', 'timestamp': '17304192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'date': 'Nov 2, 2024', 'timestamp': '17305056...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'date': 'Nov 3, 2024', 'timestamp': '17305920...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'date': 'Nov 4, 2024', 'timestamp': '17306784...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'date': 'Nov 5, 2024', 'timestamp': '17307648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'date': 'Nov 6, 2024', 'timestamp': '17308512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'date': 'Nov 7, 2024', 'timestamp': '17309376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'date': 'Nov 8, 2024', 'timestamp': '17310240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'date': 'Nov 9, 2024', 'timestamp': '17311104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'date': 'Nov 10, 2024', 'timestamp': '1731196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'date': 'Nov 11, 2024', 'timestamp': '1731283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'date': 'Nov 12, 2024', 'timestamp': '1731369...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'date': 'Nov 13, 2024', 'timestamp': '1731456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'date': 'Nov 14, 2024', 'timestamp': '1731542...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        timeline_data\n",
       "0   {'date': 'Oct 14, 2024', 'timestamp': '1728864...\n",
       "1   {'date': 'Oct 15, 2024', 'timestamp': '1728950...\n",
       "2   {'date': 'Oct 16, 2024', 'timestamp': '1729036...\n",
       "3   {'date': 'Oct 17, 2024', 'timestamp': '1729123...\n",
       "4   {'date': 'Oct 18, 2024', 'timestamp': '1729209...\n",
       "5   {'date': 'Oct 19, 2024', 'timestamp': '1729296...\n",
       "6   {'date': 'Oct 20, 2024', 'timestamp': '1729382...\n",
       "7   {'date': 'Oct 21, 2024', 'timestamp': '1729468...\n",
       "8   {'date': 'Oct 22, 2024', 'timestamp': '1729555...\n",
       "9   {'date': 'Oct 23, 2024', 'timestamp': '1729641...\n",
       "10  {'date': 'Oct 24, 2024', 'timestamp': '1729728...\n",
       "11  {'date': 'Oct 25, 2024', 'timestamp': '1729814...\n",
       "12  {'date': 'Oct 26, 2024', 'timestamp': '1729900...\n",
       "13  {'date': 'Oct 27, 2024', 'timestamp': '1729987...\n",
       "14  {'date': 'Oct 28, 2024', 'timestamp': '1730073...\n",
       "15  {'date': 'Oct 29, 2024', 'timestamp': '1730160...\n",
       "16  {'date': 'Oct 30, 2024', 'timestamp': '1730246...\n",
       "17  {'date': 'Oct 31, 2024', 'timestamp': '1730332...\n",
       "18  {'date': 'Nov 1, 2024', 'timestamp': '17304192...\n",
       "19  {'date': 'Nov 2, 2024', 'timestamp': '17305056...\n",
       "20  {'date': 'Nov 3, 2024', 'timestamp': '17305920...\n",
       "21  {'date': 'Nov 4, 2024', 'timestamp': '17306784...\n",
       "22  {'date': 'Nov 5, 2024', 'timestamp': '17307648...\n",
       "23  {'date': 'Nov 6, 2024', 'timestamp': '17308512...\n",
       "24  {'date': 'Nov 7, 2024', 'timestamp': '17309376...\n",
       "25  {'date': 'Nov 8, 2024', 'timestamp': '17310240...\n",
       "26  {'date': 'Nov 9, 2024', 'timestamp': '17311104...\n",
       "27  {'date': 'Nov 10, 2024', 'timestamp': '1731196...\n",
       "28  {'date': 'Nov 11, 2024', 'timestamp': '1731283...\n",
       "29  {'date': 'Nov 12, 2024', 'timestamp': '1731369...\n",
       "30  {'date': 'Nov 13, 2024', 'timestamp': '1731456...\n",
       "31  {'date': 'Nov 14, 2024', 'timestamp': '1731542..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6604336-75cb-446a-a09e-6e8bcf7ebf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interest Over Time (Cleaned) DataFrame:\n",
      "            date   timestamp  \\\n",
      "0   Oct 14, 2024  1728864000   \n",
      "1   Oct 15, 2024  1728950400   \n",
      "2   Oct 16, 2024  1729036800   \n",
      "3   Oct 17, 2024  1729123200   \n",
      "4   Oct 18, 2024  1729209600   \n",
      "5   Oct 19, 2024  1729296000   \n",
      "6   Oct 20, 2024  1729382400   \n",
      "7   Oct 21, 2024  1729468800   \n",
      "8   Oct 22, 2024  1729555200   \n",
      "9   Oct 23, 2024  1729641600   \n",
      "10  Oct 24, 2024  1729728000   \n",
      "11  Oct 25, 2024  1729814400   \n",
      "12  Oct 26, 2024  1729900800   \n",
      "13  Oct 27, 2024  1729987200   \n",
      "14  Oct 28, 2024  1730073600   \n",
      "15  Oct 29, 2024  1730160000   \n",
      "16  Oct 30, 2024  1730246400   \n",
      "17  Oct 31, 2024  1730332800   \n",
      "18   Nov 1, 2024  1730419200   \n",
      "19   Nov 2, 2024  1730505600   \n",
      "20   Nov 3, 2024  1730592000   \n",
      "21   Nov 4, 2024  1730678400   \n",
      "22   Nov 5, 2024  1730764800   \n",
      "23   Nov 6, 2024  1730851200   \n",
      "24   Nov 7, 2024  1730937600   \n",
      "25   Nov 8, 2024  1731024000   \n",
      "26   Nov 9, 2024  1731110400   \n",
      "27  Nov 10, 2024  1731196800   \n",
      "28  Nov 11, 2024  1731283200   \n",
      "29  Nov 12, 2024  1731369600   \n",
      "30  Nov 13, 2024  1731456000   \n",
      "31  Nov 14, 2024  1731542400   \n",
      "\n",
      "                                               values partial_data  \n",
      "0   [{'query': 'generative AI', 'value': '94', 'ex...          NaN  \n",
      "1   [{'query': 'generative AI', 'value': '89', 'ex...          NaN  \n",
      "2   [{'query': 'generative AI', 'value': '92', 'ex...          NaN  \n",
      "3   [{'query': 'generative AI', 'value': '85', 'ex...          NaN  \n",
      "4   [{'query': 'generative AI', 'value': '77', 'ex...          NaN  \n",
      "5   [{'query': 'generative AI', 'value': '90', 'ex...          NaN  \n",
      "6   [{'query': 'generative AI', 'value': '57', 'ex...          NaN  \n",
      "7   [{'query': 'generative AI', 'value': '90', 'ex...          NaN  \n",
      "8   [{'query': 'generative AI', 'value': '100', 'e...          NaN  \n",
      "9   [{'query': 'generative AI', 'value': '99', 'ex...          NaN  \n",
      "10  [{'query': 'generative AI', 'value': '87', 'ex...          NaN  \n",
      "11  [{'query': 'generative AI', 'value': '76', 'ex...          NaN  \n",
      "12  [{'query': 'generative AI', 'value': '91', 'ex...          NaN  \n",
      "13  [{'query': 'generative AI', 'value': '51', 'ex...          NaN  \n",
      "14  [{'query': 'generative AI', 'value': '94', 'ex...          NaN  \n",
      "15  [{'query': 'generative AI', 'value': '94', 'ex...          NaN  \n",
      "16  [{'query': 'generative AI', 'value': '82', 'ex...          NaN  \n",
      "17  [{'query': 'generative AI', 'value': '77', 'ex...          NaN  \n",
      "18  [{'query': 'generative AI', 'value': '79', 'ex...          NaN  \n",
      "19  [{'query': 'generative AI', 'value': '90', 'ex...          NaN  \n",
      "20  [{'query': 'generative AI', 'value': '62', 'ex...          NaN  \n",
      "21  [{'query': 'generative AI', 'value': '83', 'ex...          NaN  \n",
      "22  [{'query': 'generative AI', 'value': '80', 'ex...          NaN  \n",
      "23  [{'query': 'generative AI', 'value': '54', 'ex...          NaN  \n",
      "24  [{'query': 'generative AI', 'value': '78', 'ex...          NaN  \n",
      "25  [{'query': 'generative AI', 'value': '70', 'ex...          NaN  \n",
      "26  [{'query': 'generative AI', 'value': '94', 'ex...          NaN  \n",
      "27  [{'query': 'generative AI', 'value': '47', 'ex...          NaN  \n",
      "28  [{'query': 'generative AI', 'value': '88', 'ex...          NaN  \n",
      "29  [{'query': 'generative AI', 'value': '90', 'ex...          NaN  \n",
      "30  [{'query': 'generative AI', 'value': '87', 'ex...          NaN  \n",
      "31  [{'query': 'generative AI', 'value': '84', 'ex...         True  \n"
     ]
    }
   ],
   "source": [
    "# Assuming interest_df is your original DataFrame with nested 'timeline_data' dictionaries\n",
    "# Extract 'timeline_data' as a list of dictionaries\n",
    "timeline_data = interest_df['timeline_data'].tolist()\n",
    "\n",
    "# Normalize the list of dictionaries into a DataFrame\n",
    "normalized_df = pd.json_normalize(timeline_data)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Interest Over Time (Cleaned) DataFrame:\")\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32bb37a8-ba5f-41b3-8eeb-4fde369bfc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interest Over Time DataFrame (Cleaned):\n",
      "        Date   Timestamp                                             values  \\\n",
      "0 2024-10-14  1728864000  [{'query': 'generative AI', 'value': '94', 'ex...   \n",
      "1 2024-10-15  1728950400  [{'query': 'generative AI', 'value': '89', 'ex...   \n",
      "2 2024-10-16  1729036800  [{'query': 'generative AI', 'value': '92', 'ex...   \n",
      "3 2024-10-17  1729123200  [{'query': 'generative AI', 'value': '85', 'ex...   \n",
      "4 2024-10-18  1729209600  [{'query': 'generative AI', 'value': '77', 'ex...   \n",
      "\n",
      "  partial_data  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Rename columns for readability\n",
    "normalized_df = normalized_df.rename(columns={\n",
    "    'date': 'Date',\n",
    "    'timestamp': 'Timestamp',\n",
    "    'value': 'InterestValue'\n",
    "})\n",
    "\n",
    "# Convert 'Date' to a datetime format for easy time-series analysis\n",
    "normalized_df['Date'] = pd.to_datetime(normalized_df['Date'])\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Interest Over Time DataFrame (Cleaned):\")\n",
    "print(normalized_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74af41f-5198-45b7-870a-ca59450c929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>values</th>\n",
       "      <th>partial_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>1728864000</td>\n",
       "      <td>[{'query': 'generative AI', 'value': '94', 'ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>1728950400</td>\n",
       "      <td>[{'query': 'generative AI', 'value': '89', 'ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>1729036800</td>\n",
       "      <td>[{'query': 'generative AI', 'value': '92', 'ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>1729123200</td>\n",
       "      <td>[{'query': 'generative AI', 'value': '85', 'ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>1729209600</td>\n",
       "      <td>[{'query': 'generative AI', 'value': '77', 'ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Timestamp                                             values  \\\n",
       "0 2024-10-14  1728864000  [{'query': 'generative AI', 'value': '94', 'ex...   \n",
       "1 2024-10-15  1728950400  [{'query': 'generative AI', 'value': '89', 'ex...   \n",
       "2 2024-10-16  1729036800  [{'query': 'generative AI', 'value': '92', 'ex...   \n",
       "3 2024-10-17  1729123200  [{'query': 'generative AI', 'value': '85', 'ex...   \n",
       "4 2024-10-18  1729209600  [{'query': 'generative AI', 'value': '77', 'ex...   \n",
       "\n",
       "  partial_data  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840542e-6e9d-4f83-b64a-7fd0dbffcd59",
   "metadata": {},
   "source": [
    "This code allows me to get the interest by state across four years on a month basis using SERPAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3681b3-5150-4cc8-969e-c7d8ebc07483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SerpAPI key and endpoint\n",
    "api_key = 'd9a1fe6b31333b92203f396c6b8770a363fe43e109bdab8e5cb49106bcb7897e'\n",
    "endpoint = 'https://serpapi.com/search.json'\n",
    "\n",
    "# Query parameters\n",
    "query = 'generative AI'\n",
    "start_date = datetime.now() - timedelta(weeks=208)  # 4 years ago\n",
    "end_date = datetime.now()\n",
    "\n",
    "# List of U.S. states\n",
    "us_states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\",\n",
    "    \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\",\n",
    "    \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\",\n",
    "    \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "monthly_data = []\n",
    "\n",
    "# Loop through each state and fetch monthly data\n",
    "for state in us_states:\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date < end_date:\n",
    "        # Define the monthly date range\n",
    "        next_date = current_date + timedelta(days=30)\n",
    "        date_range = f\"{current_date.strftime('%Y-%m-%d')} {next_date.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "        # API parameters\n",
    "        params = {\n",
    "            'engine': 'google_trends',\n",
    "            'q': query,\n",
    "            'geo': f\"US-{state}\",  # State-level data\n",
    "            'date': date_range,\n",
    "            'api_key': api_key\n",
    "        }\n",
    "\n",
    "        # Fetch data from SerpAPI\n",
    "        response = requests.get(endpoint, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            interest_data = data.get(\"interest_over_time\", [])\n",
    "\n",
    "            if isinstance(interest_data, list):\n",
    "                for entry in interest_data:\n",
    "                    if isinstance(entry, dict):\n",
    "                        monthly_data.append({\n",
    "                            \"State\": state,\n",
    "                            \"Date\": entry.get(\"date\"),\n",
    "                            \"InterestValue\": entry.get(\"value\", 0)  # Default to 0 if missing\n",
    "                        })\n",
    "\n",
    "        # Move to the next month\n",
    "        current_date = next_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bb1f4-0361-4a5a-b34e-77dc9dbd8eff",
   "metadata": {},
   "source": [
    "This is the code used for the CSV files manually pulled from google trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3867305f-1701-4fdb-b1bd-1276d3ba9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     State  (4/1/23  (4/1/24  (8/1/23  \\\n",
      "District of Columbia  District of Columbia      100      100      100   \n",
      "Massachusetts                Massachusetts       55       59       62   \n",
      "California                      California       51       41       45   \n",
      "Washington                      Washington       50       49       51   \n",
      "New York                          New York       41       43       36   \n",
      "Virginia                          Virginia       37       42       44   \n",
      "New Jersey                      New Jersey       37       41       41   \n",
      "Illinois                          Illinois       29       33       31   \n",
      "Colorado                          Colorado       29       29       32   \n",
      "Hawaii                              Hawaii       25       25       19   \n",
      "Connecticut                    Connecticut       24       37       37   \n",
      "Maryland                          Maryland       22       35       25   \n",
      "Oregon                              Oregon       21       30       30   \n",
      "Pennsylvania                  Pennsylvania       20       30       26   \n",
      "Georgia                            Georgia       20       33       30   \n",
      "Utah                                  Utah       19       26       25   \n",
      "Texas                                Texas       19       29       29   \n",
      "Nebraska                          Nebraska       17       14       20   \n",
      "North Carolina              North Carolina       16       28       25   \n",
      "Minnesota                        Minnesota       16       35       26   \n",
      "Nevada                              Nevada       15       24       20   \n",
      "Florida                            Florida       15       25       21   \n",
      "Michigan                          Michigan       14       24       21   \n",
      "Wisconsin                        Wisconsin       13       18       27   \n",
      "Ohio                                  Ohio       13       24       19   \n",
      "Arizona                            Arizona       12       25       27   \n",
      "Missouri                          Missouri       12       22       15   \n",
      "Tennessee                        Tennessee       10       24       14   \n",
      "South Carolina              South Carolina        9       14       13   \n",
      "Indiana                            Indiana        9       17       18   \n",
      "Alaska                              Alaska        0        0        0   \n",
      "New Hampshire                New Hampshire        0       22       34   \n",
      "New Mexico                      New Mexico        0        0        0   \n",
      "North Dakota                  North Dakota        0        0        0   \n",
      "Montana                            Montana        0        0        0   \n",
      "Mississippi                    Mississippi        0       11       10   \n",
      "Oklahoma                          Oklahoma        0       13        9   \n",
      "Maine                                Maine        0       18       26   \n",
      "Louisiana                        Louisiana        0       14       11   \n",
      "Rhode Island                  Rhode Island        0       28       33   \n",
      "Kentucky                          Kentucky        0       20       13   \n",
      "South Dakota                  South Dakota        0        0        0   \n",
      "Kansas                              Kansas        0       33       13   \n",
      "Idaho                                Idaho        0       19       24   \n",
      "Iowa                                  Iowa        0       10       21   \n",
      "Delaware                          Delaware        0        0       29   \n",
      "Vermont                            Vermont        0       39       32   \n",
      "Arkansas                          Arkansas        0       20        0   \n",
      "Alabama                            Alabama        0       15       13   \n",
      "West Virginia                West Virginia        0        0        0   \n",
      "Wyoming                            Wyoming        0        0        0   \n",
      "\n",
      "                      (8/1/24  (12/1/22  (12/1/23  (2/1/23  (2/1/24  (1/1/24  \\\n",
      "District of Columbia      100         0       100      100      100      100   \n",
      "Massachusetts              56         0        55       52       58       54   \n",
      "California                 47       100        41       68       47       43   \n",
      "Washington                 46        72        47       64       51       41   \n",
      "New York                   98        48        37       50       42       36   \n",
      "Virginia                   52        40        40       25       44       43   \n",
      "New Jersey                 43        35        41       41       42       44   \n",
      "Illinois                   34        29        31       30       35       34   \n",
      "Colorado                   39         0        34       23       36       35   \n",
      "Hawaii                     26         0        31        0       25       26   \n",
      "Connecticut                31         0        36        0       27       33   \n",
      "Maryland                   47         0        31       31       41       34   \n",
      "Oregon                     41         0        24       39       25       23   \n",
      "Pennsylvania               26        27        27       24       29       24   \n",
      "Georgia                    36         0        25       15       33       28   \n",
      "Utah                       32         0        36        0       23       31   \n",
      "Texas                      34        13        25       20       31       26   \n",
      "Nebraska                   29         0         0        0       19       13   \n",
      "North Carolina             32         0        26       22       29       28   \n",
      "Minnesota                  30         0        25       27       34       27   \n",
      "Nevada                     30         0        21        0       14       24   \n",
      "Florida                    24        29        18       13       21       18   \n",
      "Michigan                   24         0        20       15       22       21   \n",
      "Wisconsin                  19         0        25       22       23       17   \n",
      "Ohio                       23        32        20       20       25       21   \n",
      "Arizona                    26         0        25       17       23       20   \n",
      "Missouri                   23         0        15       16       19       20   \n",
      "Tennessee                  21         0        17       18       22       15   \n",
      "South Carolina             21         0        14        0       19       12   \n",
      "Indiana                    30         0        15       14       23       21   \n",
      "Alaska                      0         0         0        0        0        0   \n",
      "New Hampshire              34         0        31        0       30       26   \n",
      "New Mexico                 20         0        13        0       13       17   \n",
      "North Dakota                0         0         0        0        0        0   \n",
      "Montana                     0         0         0        0        0        0   \n",
      "Mississippi                 0         0        11        0       10       12   \n",
      "Oklahoma                   18         0        10        0       17       13   \n",
      "Maine                       0         0        27        0       20       23   \n",
      "Louisiana                  14         0        17        0       15        8   \n",
      "Rhode Island               29         0        22        0       25       31   \n",
      "Kentucky                   15         0         9        0       17        7   \n",
      "South Dakota                0         0         0        0        0        0   \n",
      "Kansas                     21         0        22        0       14       10   \n",
      "Idaho                      19         0        15        0       20       27   \n",
      "Iowa                       16         0        21        0       16       19   \n",
      "Delaware                   30         0        34        0        0        0   \n",
      "Vermont                     0         0         0        0        0       35   \n",
      "Arkansas                   19         0        11        0       14       11   \n",
      "Alabama                    20         0         7        0       11       12   \n",
      "West Virginia               0         0         0        0        0       22   \n",
      "Wyoming                     0         0         0        0        0        0   \n",
      "\n",
      "                      ...  (3/1/23  (3/1/24  (5/1/23  (5/1/24  (11/1/22  \\\n",
      "District of Columbia  ...      100      100      100      100         0   \n",
      "Massachusetts         ...       55       65       38       55        58   \n",
      "California            ...       50       52       37       51       100   \n",
      "Washington            ...       47       60       36       59        44   \n",
      "New York              ...       39       51       30       83        58   \n",
      "Virginia              ...       29       51       30       53         0   \n",
      "New Jersey            ...       34       49       28       56        51   \n",
      "Illinois              ...       20       33       22       37         0   \n",
      "Colorado              ...       23       35       18       34         0   \n",
      "Hawaii                ...        0       19        0        0         0   \n",
      "Connecticut           ...       15       28       23       37         0   \n",
      "Maryland              ...       20       40       21       45        82   \n",
      "Oregon                ...       29       32       24       34         0   \n",
      "Pennsylvania          ...       19       35       16       29         0   \n",
      "Georgia               ...       18       34       15       35         0   \n",
      "Utah                  ...       21       34       10       32         0   \n",
      "Texas                 ...       19       34       16       30        17   \n",
      "Nebraska              ...        0       28        0       19         0   \n",
      "North Carolina        ...       17       31       15       31         0   \n",
      "Minnesota             ...       22       28       16       25         0   \n",
      "Nevada                ...       22       24       15       26         0   \n",
      "Florida               ...       12       21       12       24         0   \n",
      "Michigan              ...       13       26       10       23        34   \n",
      "Wisconsin             ...       10       21       12       21        65   \n",
      "Ohio                  ...       13       22        9       25         0   \n",
      "Arizona               ...       18       26       12       26         0   \n",
      "Missouri              ...       12       23        8       25         0   \n",
      "Tennessee             ...        7       21       12       24         0   \n",
      "South Carolina        ...        9       19        7       22         0   \n",
      "Indiana               ...       13       24        8       23         0   \n",
      "Alaska                ...        0        0        0        0         0   \n",
      "New Hampshire         ...        0       21       20       44         0   \n",
      "New Mexico            ...        0        0        0       25         0   \n",
      "North Dakota          ...        0        0        0        0         0   \n",
      "Montana               ...        0       27       16        0         0   \n",
      "Mississippi           ...        0        0        0        0         0   \n",
      "Oklahoma              ...        0       14        5       18         0   \n",
      "Maine                 ...        0        0       13       37         0   \n",
      "Louisiana             ...        0       13        0       18         0   \n",
      "Rhode Island          ...        0       26       13        0         0   \n",
      "Kentucky              ...        0       23        9       14         0   \n",
      "South Dakota          ...        0       37        0        0         0   \n",
      "Kansas                ...        0       23       12       26         0   \n",
      "Idaho                 ...        0        0       10       17         0   \n",
      "Iowa                  ...        0       19       11       29         0   \n",
      "Delaware              ...        0       39        0       39         0   \n",
      "Vermont               ...        0        0        0        0         0   \n",
      "Arkansas              ...        0       14        8       16         0   \n",
      "Alabama               ...        0       15        4       13         0   \n",
      "West Virginia         ...        0        0        0        0         0   \n",
      "Wyoming               ...        0        0        0        0         0   \n",
      "\n",
      "                      (11/1/23  (10/1/23  (10/1/24  (9/1/23  (9/1/24  \n",
      "District of Columbia       100       100       100      100      100  \n",
      "Massachusetts               49        55        68       59       55  \n",
      "California                  33        40        57       42       44  \n",
      "Washington                  43        49        63       47       38  \n",
      "New York                    32        37        96       34       81  \n",
      "Virginia                    36        35        59       41       47  \n",
      "New Jersey                  33        37        47       40       39  \n",
      "Illinois                    28        31        44       30       38  \n",
      "Colorado                    27        29        39       28       32  \n",
      "Hawaii                      15        21        31       17       30  \n",
      "Connecticut                 29        25        36       33       30  \n",
      "Maryland                    28        30        51       32       43  \n",
      "Oregon                      20        27        35       21       34  \n",
      "Pennsylvania                26        25        38       26       33  \n",
      "Georgia                     24        25        39       27       34  \n",
      "Utah                        20        22        34       21       27  \n",
      "Texas                       23        24        39       26       31  \n",
      "Nebraska                     0        12        20       14       30  \n",
      "North Carolina              24        22        38       26       32  \n",
      "Minnesota                   21        30        35       21       26  \n",
      "Nevada                      27        22        39       15       26  \n",
      "Florida                     15        17        27       17       22  \n",
      "Michigan                    15        18        38       21       22  \n",
      "Wisconsin                   16        21        39       16       26  \n",
      "Ohio                        16        18        29       17       31  \n",
      "Arizona                     18        19        36       26       31  \n",
      "Missouri                    17        17        40       20       28  \n",
      "Tennessee                   14        16        31       18       19  \n",
      "South Carolina              10        11        25       12       18  \n",
      "Indiana                     13        17        38       19       27  \n",
      "Alaska                       0         0         0        0        0  \n",
      "New Hampshire               32        24        70       29       25  \n",
      "New Mexico                  11         0         0        0        0  \n",
      "North Dakota                 0         0         0        0        0  \n",
      "Montana                      0        20         0        0        0  \n",
      "Mississippi                  0        12        16        0       14  \n",
      "Oklahoma                    13        19        24       10       19  \n",
      "Maine                        0        15        26       16       29  \n",
      "Louisiana                    9        11        16       15       17  \n",
      "Rhode Island                 0        23        43       22       23  \n",
      "Kentucky                    14        14        20       10       23  \n",
      "South Dakota                 0         0         0        0        0  \n",
      "Kansas                      16        19        30       12       31  \n",
      "Idaho                       10        16        32       20        0  \n",
      "Iowa                        11        13        39       14       30  \n",
      "Delaware                     0         0        35        0        0  \n",
      "Vermont                      0        27         0        0        0  \n",
      "Arkansas                    11        14        28       10       19  \n",
      "Alabama                     11        12        25       10       21  \n",
      "West Virginia                0         0         0        0        0  \n",
      "Wyoming                      0         0         0        0        0  \n",
      "\n",
      "[51 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to parse and combine CSV files\n",
    "def parse_csv_files(folder_path):\n",
    "    combined_data = {}\n",
    "\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Extract the date from the 3rd line's second part\n",
    "        header_line = lines[2].strip()\n",
    "        date_info = header_line.split(\",\")[1].split(\":\")[1].strip()\n",
    "        date = date_info.split(\" - \")[0]\n",
    "\n",
    "        # Process the data starting from the 4th line\n",
    "        for line in lines[3:]:\n",
    "            if line.strip():  # Ignore empty lines\n",
    "                parts = line.strip().split(\",\")\n",
    "                if len(parts) == 2:  # Only process lines with 2 parts (State, Score)\n",
    "                    state, score = parts[0], parts[1]\n",
    "                    score = pd.to_numeric(score, errors='coerce')  # Convert to numeric\n",
    "                    if pd.isna(score):  # Handle missing values\n",
    "                        score = 0\n",
    "                    \n",
    "                    if state not in combined_data:\n",
    "                        combined_data[state] = {'State': state}\n",
    "                    combined_data[state][date] = combined_data[state].get(date, 0) + score\n",
    "\n",
    "    # Create a DataFrame from the combined data\n",
    "    final_data = pd.DataFrame.from_dict(combined_data, orient='index')\n",
    "    return final_data\n",
    "\n",
    "# Define the folder path where your CSV files are stored\n",
    "folder_path = 'C:\\\\Users\\\\rmbro\\\\OneDrive\\\\Documents\\\\Comp_3\\\\Final\\\\Google_Trends'\n",
    "\n",
    "# Parse and combine the CSV files\n",
    "US_Trends = parse_csv_files(folder_path)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(US_Trends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "560d1823-50a8-46e4-88e8-7aaf02d44235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'US_Trends.csv' in the current working directory.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file in the current working directory\n",
    "US_Trends.to_csv('US_Trends.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved as 'US_Trends.csv' in the current working directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a86df293-0f61-4f6d-ad8f-8a73eb71b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved as Total_US_Interest.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmbro\\AppData\\Local\\Temp\\ipykernel_9352\\3395785988.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Day'] = pd.to_datetime(df['Day'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# cleaning total us data info.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:\\\\Users\\\\rmbro\\\\OneDrive\\\\Documents\\\\Comp_3\\\\Final\\\\multiTimeline.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean and process the DataFrame\n",
    "df.reset_index(inplace=True)  # Reset the index\n",
    "df.columns = ['Day', 'Trend_Score']  # Rename columns\n",
    "\n",
    "# Convert the 'Day' column to datetime\n",
    "df['Day'] = pd.to_datetime(df['Day'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df.dropna(subset=['Day'], inplace=True)\n",
    "\n",
    "# Convert 'Trend_Score' to numeric\n",
    "df['Trend_Score'] = pd.to_numeric(df['Trend_Score'], errors='coerce')\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "output_file = 'Total_US_Interest.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned CSV saved as {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
